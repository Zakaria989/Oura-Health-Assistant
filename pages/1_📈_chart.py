from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
import streamlit as st
import numpy as np
import os
from dotenv import load_dotenv
import time

st.set_page_config(page_title="Plots", page_icon="ðŸ“ˆ")

# Load api from .env
load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")

DB_FAISS_PATH = "data/db_faiss"

# Loading the model
def load_llm():
    llm = ChatOpenAI(
        model="gpt-3.5-turbo-0613",
        openai_api_key=openai_api_key
    )
    return llm

def conversational_chat(query):
    print("Running query")
    result = chain({"question": query, "chat_history": st.session_state['history']})
    st.session_state['history'].append((query,result["answer"]))
    print(result["answer"])
    return result["answer"]

embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key, model="text-embedding-ada-002")
db = FAISS.load_local(DB_FAISS_PATH,embeddings)
llm = load_llm()
chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=db.as_retriever())

if 'history' not in st.session_state:
    st.session_state['history'] = []

if user_input := st.text_input("Enter your message"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                response = conversational_chat(user_input)
                placeholder = st.empty()
        message = {"role": "assistant", "content": response}
        st.session_state.messages.append(message)
        with st.chat_message("assistant"):
            st.write(response)

st.markdown("# What chart do you want to visualize?")
st.sidebar.header("Plotting charts")
st.write(
    """This demo illustrates a combination of plotting and animation with
Streamlit and is generated by user prompt to GPT"""
)

progress_bar = st.sidebar.progress(0)
status_text = st.sidebar.empty()
last_rows = np.random.randn(1, 1)
chart = st.line_chart(last_rows)

for i in range(1, 101):
    new_rows = last_rows[-1, :] + np.random.randn(5, 1).cumsum(axis=0)
    status_text.text("%i%% Complete" % i)
    chart.add_rows(new_rows)
    progress_bar.progress(i)
    last_rows = new_rows
    time.sleep(0.05)

progress_bar.empty()

# st.button("Re-run")
